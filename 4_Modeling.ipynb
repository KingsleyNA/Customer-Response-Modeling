{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    ">### In here, I will analyze result from 10 tried and tested models. After that, I will make a few deductions for our perusal. Note that, you may fork this notebook and help others see other dimensions to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, let me import the libraries I will need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Wertygrams\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as m\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, I will the define the set of the 10 classifiers I have in mind to tackle the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),\n",
    "               'XGBoost Classifier':XGBClassifier(),\n",
    "               'Adaptive Boosting Classifier':AdaBoostClassifier(),\n",
    "               'Linear Discriminant Analysis':LinearDiscriminantAnalysis(),\n",
    "               'Logistic Regression':LogisticRegression(),\n",
    "               'Random Forest Classifier': RandomForestClassifier(),\n",
    "               'K Nearest Neighbour':KNeighborsClassifier(8),\n",
    "               'Decision Tree Classifier':DecisionTreeClassifier(),\n",
    "               'Gaussian Naive Bayes Classifier':GaussianNB(),\n",
    "               'Support Vector Classifier':SVC(probability=True),}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop, drop, drop! Next, I will drop all the fields that failed my causality test. That's why I went to the limit of verifying causal variables in the 3rd notebook of this repository. \n",
    ">### Note: the dataframe at this point is the 2.5MB one, not the original one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdata = df.drop(['y','duration','default','euribor3m','numEmployed','pdays','empVarRate','contact', 'consPriceIdx'],axis=1)\n",
    "ydata = df['y']\n",
    "\n",
    "print(Xdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_cols = [\n",
    "    \"Classifier\", \n",
    "    \"Accuracy\",\n",
    "    \"Precision Score\",\n",
    "    \"Recall Score\",\n",
    "    \"F1-Score\",\n",
    "    \"roc-auc_Score\"\n",
    "]\n",
    "#metrics_cols = []\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "#metric = pd.DataFrame(columns=metrics_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "rs = StratifiedShuffleSplit(n_splits=3, test_size=0.3,random_state=0)\n",
    "rs.get_n_splits(Xdata,ydata)\n",
    "\n",
    "for Name,classify in classifiers.items():\n",
    "    for train_index, test_index in rs.split(Xdata,ydata):\n",
    "        \n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X,X_test = Xdata.iloc[train_index], Xdata.iloc[test_index]\n",
    "        y,y_test = ydata.iloc[train_index], ydata.iloc[test_index]\n",
    "\n",
    "        # Scaling of Features \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc_X = StandardScaler()\n",
    "        X = sc_X.fit_transform(X)\n",
    "        X_test = sc_X.transform(X_test)\n",
    "        cls = classify\n",
    "        cls =cls.fit(X,y)\n",
    "        y_out = cls.predict(X_test)\n",
    "        accuracy = m.accuracy_score(y_test,y_out)\n",
    "        precision = m.precision_score(y_test,y_out,average='macro')\n",
    "        recall = m.recall_score(y_test,y_out,average='macro')\n",
    "        roc_auc = roc_auc_score(y_out,y_test)\n",
    "        f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "        log_entry = pd.DataFrame([[Name,accuracy,precision,recall,f1_score,roc_auc]], columns=log_cols)\n",
    "        #metric_entry = pd.DataFrame([[precision,recall,f1_score,roc_auc]], columns=metrics_cols)\n",
    "        log = log.append(log_entry)\n",
    "        #metric = metric.append(metric_entry)\n",
    "        \n",
    "print(log)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(log['Recall Score'], log['Precision Score'], color='navy',\n",
    "         label='Precision-Recall')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
